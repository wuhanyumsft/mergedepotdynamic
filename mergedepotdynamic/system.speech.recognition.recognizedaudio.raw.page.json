{"content":"    \r\n    <h1 id=\"System_Speech_Recognition_RecognizedAudio\">\r\n      <span class=\"lang-csharp\">RecognizedAudio</span>\r\n        Class\r\n    </h1>\r\n    \r\n    \r\n    <nav id=\"center-doc-outline\" class=\"doc-outline\" ms.cmpgrp=\"intopic toc\" role=\"navigation\" aria-label=\"On page navigation\">\r\n      <h3>In this Article</h3>\r\n    </nav><div class=\"summary\">\r\n    \t<p>Represents audio input that is associated with a <a class=\"xref\" href=\"system.speech.recognition.recognitionresult\" data-linktype=\"relative-path\">RecognitionResult</a>.</p>\n\r\n    </div><h2>Syntax</h2>\r\n    \r\n    \t<h3>Declaration</h3>\r\n    \t<pre class=\"memberDeclaration\"><code class=\"csharp lang-csharp\">public class RecognizedAudio</code></pre>\r\n    \r\n    \r\n    \r\n    <h3>Inheritance Hierarchy</h3>\r\n    <ul class=\"inheritance\">\r\n        <li class=\"l0\">\r\n          <div class=\"lang-csharp\">\r\n            <a class=\"xref\" href=\"system.object\" data-linktype=\"relative-path\">System.Object</a>\r\n          </div>\r\n        </li>\r\n      <li class=\"l1\">\r\n        <div class=\"xref\">\r\n          <div class=\"lang-csharp\">RecognizedAudio</div>\r\n        </div>\r\n      </li>\r\n    </ul>\r\n    \r\n      <div class=\"referencebox inheritedMembers\">\r\n        <h3>Inherited Members</h3>\r\n        <h4></h4>\r\n          <div class=\"lang-csharp\">\r\n            <a class=\"xref\" href=\"system.object#System_Object_Equals_System_Object_\" data-linktype=\"relative-path\">Equals(Object)</a>\r\n          </div>\r\n          , \r\n          <div class=\"lang-csharp\">\r\n            <a class=\"xref\" href=\"system.object#System_Object_Equals_System_Object_System_Object_\" data-linktype=\"relative-path\">Equals(Object,Object)</a>\r\n          </div>\r\n          , \r\n          <div class=\"lang-csharp\">\r\n            <a class=\"xref\" href=\"system.object#System_Object_GetHashCode\" data-linktype=\"relative-path\">GetHashCode()</a>\r\n          </div>\r\n          , \r\n          <div class=\"lang-csharp\">\r\n            <a class=\"xref\" href=\"system.object#System_Object_GetType\" data-linktype=\"relative-path\">GetType()</a>\r\n          </div>\r\n          , \r\n          <div class=\"lang-csharp\">\r\n            <a class=\"xref\" href=\"system.object#System_Object_MemberwiseClone\" data-linktype=\"relative-path\">MemberwiseClone()</a>\r\n          </div>\r\n          , \r\n          <div class=\"lang-csharp\">\r\n            <a class=\"xref\" href=\"system.object#System_Object_ReferenceEquals_System_Object_System_Object_\" data-linktype=\"relative-path\">ReferenceEquals(Object,Object)</a>\r\n          </div>\r\n          , \r\n          <div class=\"lang-csharp\">\r\n            <a class=\"xref\" href=\"system.object#System_Object_ToString\" data-linktype=\"relative-path\">ToString()</a>\r\n          </div>\r\n          \r\n      </div>\r\n    \r\n    \r\n      <h2>Remarks</h2>\r\n      <p>A speech recognizer generates information about the audio input as part of the recognition operation. To access the recognized audio, use the <a class=\"xref\" href=\"system.speech.recognition.recognitionresult#System_Speech_Recognition_RecognitionResult_Audio_\" data-linktype=\"relative-path\">Audio</a> property or the <a class=\"xref\" href=\"system.speech.recognition.recognitionresult#System_Speech_Recognition_RecognitionResult_GetAudioForWordRange_\" data-linktype=\"relative-path\">GetAudioForWordRange</a> method of the <a class=\"xref\" href=\"system.speech.recognition.recognitionresult\" data-linktype=\"relative-path\">RecognitionResult</a>.  </p>\n<p> A recognition result can be produced by the following events and methods of the <a class=\"xref\" href=\"system.speech.recognition.speechrecognizer\" data-linktype=\"relative-path\">SpeechRecognizer</a> and <a class=\"xref\" href=\"system.speech.recognition.speechrecognitionengine\" data-linktype=\"relative-path\">SpeechRecognitionEngine</a> classes:  </p>\n<ul>\n<li><p>Events:  </p>\n<ul>\n<li><p><a class=\"xref\" href=\"system.speech.recognition.speechrecognitionengine#System_Speech_Recognition_SpeechRecognitionEngine_SpeechHypothesized\" data-linktype=\"relative-path\">System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized</a> and <a class=\"xref\" href=\"system.speech.recognition.speechrecognizer#System_Speech_Recognition_SpeechRecognizer_SpeechHypothesized\" data-linktype=\"relative-path\">System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized</a>  </p>\n</li>\n<li><p><a class=\"xref\" href=\"system.speech.recognition.speechrecognitionengine#System_Speech_Recognition_SpeechRecognitionEngine_SpeechRecognitionRejected\" data-linktype=\"relative-path\">System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected</a> and <a class=\"xref\" href=\"system.speech.recognition.speechrecognizer#System_Speech_Recognition_SpeechRecognizer_SpeechRecognitionRejected\" data-linktype=\"relative-path\">System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected</a>  </p>\n</li>\n<li><p><a class=\"xref\" href=\"system.speech.recognition.speechrecognitionengine#System_Speech_Recognition_SpeechRecognitionEngine_SpeechRecognized\" data-linktype=\"relative-path\">System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized</a> and <a class=\"xref\" href=\"system.speech.recognition.speechrecognizer#System_Speech_Recognition_SpeechRecognizer_SpeechRecognized\" data-linktype=\"relative-path\">System.Speech.Recognition.SpeechRecognizer.SpeechRecognized</a>  </p>\n</li>\n<li><p><a class=\"xref\" href=\"system.speech.recognition.speechrecognitionengine#System_Speech_Recognition_SpeechRecognitionEngine_EmulateRecognizeCompleted\" data-linktype=\"relative-path\">System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeCompleted</a> and <a class=\"xref\" href=\"system.speech.recognition.speechrecognizer#System_Speech_Recognition_SpeechRecognizer_EmulateRecognizeCompleted\" data-linktype=\"relative-path\">System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted</a>  </p>\n</li>\n<li><a class=\"xref\" href=\"system.speech.recognition.speechrecognitionengine#System_Speech_Recognition_SpeechRecognitionEngine_RecognizeCompleted\" data-linktype=\"relative-path\">System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted</a>  \n</li>\n</ul>\n</li>\n<li><p>Methods:  </p>\n<ul>\n<li><p><a class=\"xref\" href=\"system.speech.recognition.speechrecognitionengine#System_Speech_Recognition_SpeechRecognitionEngine_EmulateRecognize_\" data-linktype=\"relative-path\">EmulateRecognize</a> and <a class=\"xref\" href=\"system.speech.recognition.speechrecognizer#System_Speech_Recognition_SpeechRecognizer_EmulateRecognize_\" data-linktype=\"relative-path\">EmulateRecognize</a>  </p>\n</li>\n<li><p><a class=\"xref\" href=\"system.speech.recognition.speechrecognitionengine#System_Speech_Recognition_SpeechRecognitionEngine_EmulateRecognizeAsync_\" data-linktype=\"relative-path\">EmulateRecognizeAsync</a> and <a class=\"xref\" href=\"system.speech.recognition.speechrecognizer#System_Speech_Recognition_SpeechRecognizer_EmulateRecognizeAsync_\" data-linktype=\"relative-path\">EmulateRecognizeAsync</a>  </p>\n</li>\n<li><a class=\"xref\" href=\"system.speech.recognition.speechrecognitionengine#System_Speech_Recognition_SpeechRecognitionEngine_Recognize_\" data-linktype=\"relative-path\">Recognize</a>  \n</li>\n<li><a class=\"xref\" href=\"system.speech.recognition.speechrecognitionengine#System_Speech_Recognition_SpeechRecognitionEngine_RecognizeAsync_\" data-linktype=\"relative-path\">RecognizeAsync</a>  \n\n</li>\n</ul>\n</li>\n</ul>\n<div class=\"IMPORTANT\"><h5>Important</h5><p> A recognition result produced by emulated speech recognition does not contain recognized audio. For such a recognition result, its <a class=\"xref\" href=\"system.speech.recognition.recognitionresult#System_Speech_Recognition_RecognitionResult_Audio_\" data-linktype=\"relative-path\">Audio</a> property returns <code>null</code> and its <a class=\"xref\" href=\"system.speech.recognition.recognitionresult#System_Speech_Recognition_RecognitionResult_GetAudioForWordRange_\" data-linktype=\"relative-path\">GetAudioForWordRange</a> method throws an exception. For more information about emulated speech recognition, see the <code>EmulateRecognize</code> and <code>EmulateRecognizeAsync</code> methods of the <a class=\"xref\" href=\"system.speech.recognition.speechrecognizer\" data-linktype=\"relative-path\">SpeechRecognizer</a> and <a class=\"xref\" href=\"system.speech.recognition.speechrecognitionengine\" data-linktype=\"relative-path\">SpeechRecognitionEngine</a> classes.</p>\n</div>\n\r\n    \r\n    \r\n    <h2>Properties\r\n     summary</h2>\r\n    \r\n    <table class=\"nameValue\">\r\n        <tr class=\" enable-platform-filter\">\r\n          <td>\r\n            <div class=\"lang-csharp\"><a href=\"#System_Speech_Recognition_RecognizedAudio_AudioPosition\" data-linktype=\"self-bookmark\">AudioPosition</a></div>\r\n          </td>\r\n            <td>\r\n            <p>Gets the location in the input audio stream for the start of the recognized audio.</p>\n\r\n            </td>\r\n        </tr>\r\n        <tr class=\" enable-platform-filter\">\r\n          <td>\r\n            <div class=\"lang-csharp\"><a href=\"#System_Speech_Recognition_RecognizedAudio_Duration\" data-linktype=\"self-bookmark\">Duration</a></div>\r\n          </td>\r\n            <td>\r\n            <p>Gets the duration of the input audio stream for the recognized audio.</p>\n\r\n            </td>\r\n        </tr>\r\n        <tr class=\" enable-platform-filter\">\r\n          <td>\r\n            <div class=\"lang-csharp\"><a href=\"#System_Speech_Recognition_RecognizedAudio_Format\" data-linktype=\"self-bookmark\">Format</a></div>\r\n          </td>\r\n            <td>\r\n            <p>Gets the format of the audio processed by a recognition engine.</p>\n\r\n            </td>\r\n        </tr>\r\n        <tr class=\" enable-platform-filter\">\r\n          <td>\r\n            <div class=\"lang-csharp\"><a href=\"#System_Speech_Recognition_RecognizedAudio_StartTime\" data-linktype=\"self-bookmark\">StartTime</a></div>\r\n          </td>\r\n            <td>\r\n            <p>Gets the system time at the start of the recognition operation.</p>\n\r\n            </td>\r\n        </tr>\r\n    </table>\r\n    <h2>Methods\r\n     summary</h2>\r\n    \r\n    <table class=\"nameValue\">\r\n        <tr class=\" enable-platform-filter\">\r\n          <td>\r\n            <div class=\"lang-csharp\"><a href=\"#System_Speech_Recognition_RecognizedAudio_GetRange_System_TimeSpan_System_TimeSpan_\" data-linktype=\"self-bookmark\">GetRange(TimeSpan,TimeSpan)</a></div>\r\n          </td>\r\n            <td>\r\n            <p>Selects and returns a section of the current recognized audio as binary data.</p>\n\r\n            </td>\r\n        </tr>\r\n        <tr class=\" enable-platform-filter\">\r\n          <td>\r\n            <div class=\"lang-csharp\"><a href=\"#System_Speech_Recognition_RecognizedAudio_WriteToAudioStream_System_IO_Stream_\" data-linktype=\"self-bookmark\">WriteToAudioStream(Stream)</a></div>\r\n          </td>\r\n            <td>\r\n            <p>Writes the entire audio to a stream as raw data.</p>\n\r\n            </td>\r\n        </tr>\r\n        <tr class=\" enable-platform-filter\">\r\n          <td>\r\n            <div class=\"lang-csharp\"><a href=\"#System_Speech_Recognition_RecognizedAudio_WriteToWaveStream_System_IO_Stream_\" data-linktype=\"self-bookmark\">WriteToWaveStream(Stream)</a></div>\r\n          </td>\r\n            <td>\r\n            <p>Writes audio to a stream in Wave format.</p>\n\r\n            </td>\r\n        </tr>\r\n    </table>\r\n    <section class=\"memberGroup\">\r\n      <header class=\"header enable-platform-filter\" id=\"properties\">\r\n        <h2>Properties\r\n    </h2>\r\n      </header>\r\n    \r\n      <ul class=\"list-clean enable-platform-filter\">\r\n    \r\n        <li class=\" enable-platform-filter\" id=\"System_Speech_Recognition_RecognizedAudio_AudioPosition\">\r\n    \r\n            <a id=\"System_Speech_Recognition_RecognizedAudio_AudioPosition_\"></a>\r\n    \r\n    \r\n          <div class=\"memberName\">\r\n            <div class=\"lang-csharp\">AudioPosition</div>        \r\n          </div>\r\n    \r\n            <p>Gets the location in the input audio stream for the start of the recognized audio.</p>\n\r\n    \r\n            <pre class=\"memberDeclaration\"><code class=\"csharp lang-csharp\">public TimeSpan AudioPosition { get; }</code></pre>\r\n    \r\n    \r\n    \r\n    \r\n              <h4>Property Value</h4>\r\n              <ul class=\"memberDetails\">\r\n                <li>\r\n                  <div class=\"single\">                \r\n                      <div class=\"lang-csharp\"><a class=\"xref\" href=\"system.timespan\" data-linktype=\"relative-path\">TimeSpan</a></div>\r\n                  </div>\r\n                  <p>The location in the input audio stream for the start of the recognized audio.</p>\n\r\n                </li>\r\n              </ul>\r\n    \r\n    \r\n          \r\n    \r\n            <h4>Remarks</h4>\r\n            <p>This property references the position at the beginning of the recognized phrase in the input device&#39;s generated audio stream. By contrast, the <code>RecognizerAudioPosition</code> property of the <a class=\"xref\" href=\"system.speech.recognition.speechrecognitionengine\" data-linktype=\"relative-path\">SpeechRecognitionEngine</a> and <a class=\"xref\" href=\"system.speech.recognition.speechrecognizer\" data-linktype=\"relative-path\">SpeechRecognizer</a> classes reference the recognizer&#39;s position within its audio input. These positions can be different. For more information, see <a href=\"http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482\" data-linktype=\"external\">Using Speech Recognition Events</a>.  </p>\n<p> The <a class=\"xref\" href=\"system.speech.recognition.recognizedaudio#System_Speech_Recognition_RecognizedAudio_StartTime_\" data-linktype=\"relative-path\">StartTime</a> property gets the system time at the start of the recognition operation.</p>\n\r\n    \r\n            <h4>Example</h4>\r\n            <p>The following example handles the <a class=\"xref\" href=\"system.speech.recognition.speechrecognitionengine#System_Speech_Recognition_SpeechRecognitionEngine_SpeechRecognized\" data-linktype=\"relative-path\">System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized</a> or <a class=\"xref\" href=\"system.speech.recognition.speechrecognizer#System_Speech_Recognition_SpeechRecognizer_SpeechRecognized\" data-linktype=\"relative-path\">System.Speech.Recognition.SpeechRecognizer.SpeechRecognized</a> event and outputs to the console information about the recognized audio that is associated with the recognition result.  </p>\n<pre><code class=\"lang-c#\">\n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n\n  RecognitionResult result = e.Result;  \n\n  Console.WriteLine(&quot;Grammar({0}): {1}&quot;,  \n    result.Grammar.Name, result.Text);  \n\n  if (e.Result.Audio != null)  \n  {  \n    RecognizedAudio audio = e.Result.Audio;  \n\n    Console.WriteLine(&quot;   start time: {0}&quot;, audio.StartTime);  \n    Console.WriteLine(&quot;   encoding format: {0}&quot;, audio.Format.EncodingFormat);  \n    Console.WriteLine(&quot;   position: {0}, duration: {1}&quot;,  \n      audio.AudioPosition, audio.Duration);  \n  }  \n\n  // Add event handler code here.  \n}\n</code></pre>\r\n    \r\n    \r\n        </li>\r\n        <li class=\" enable-platform-filter\" id=\"System_Speech_Recognition_RecognizedAudio_Duration\">\r\n    \r\n            <a id=\"System_Speech_Recognition_RecognizedAudio_Duration_\"></a>\r\n    \r\n    \r\n          <div class=\"memberName\">\r\n            <div class=\"lang-csharp\">Duration</div>        \r\n          </div>\r\n    \r\n            <p>Gets the duration of the input audio stream for the recognized audio.</p>\n\r\n    \r\n            <pre class=\"memberDeclaration\"><code class=\"csharp lang-csharp\">public TimeSpan Duration { get; }</code></pre>\r\n    \r\n    \r\n    \r\n    \r\n              <h4>Property Value</h4>\r\n              <ul class=\"memberDetails\">\r\n                <li>\r\n                  <div class=\"single\">                \r\n                      <div class=\"lang-csharp\"><a class=\"xref\" href=\"system.timespan\" data-linktype=\"relative-path\">TimeSpan</a></div>\r\n                  </div>\r\n                  <p>The duration within the input audio stream for the recognized audio.</p>\n\r\n                </li>\r\n              </ul>\r\n    \r\n    \r\n          \r\n    \r\n    \r\n            <h4>Example</h4>\r\n            <p>The following example handles the <a class=\"xref\" href=\"system.speech.recognition.speechrecognitionengine#System_Speech_Recognition_SpeechRecognitionEngine_SpeechRecognized\" data-linktype=\"relative-path\">System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized</a> or <a class=\"xref\" href=\"system.speech.recognition.speechrecognizer#System_Speech_Recognition_SpeechRecognizer_SpeechRecognized\" data-linktype=\"relative-path\">System.Speech.Recognition.SpeechRecognizer.SpeechRecognized</a> event and outputs to the console information about the recognized audio that is associated with the recognition result.  </p>\n<pre><code class=\"lang-c#\">\n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n\n  RecognitionResult result = e.Result;  \n\n  Console.WriteLine(&quot;Grammar({0}): {1}&quot;,  \n    result.Grammar.Name, result.Text);  \n\n  if (e.Result.Audio != null)  \n  {  \n    RecognizedAudio audio = e.Result.Audio;  \n\n    Console.WriteLine(&quot;   start time: {0}&quot;, audio.StartTime);  \n    Console.WriteLine(&quot;   encoding format: {0}&quot;, audio.Format.EncodingFormat);  \n    Console.WriteLine(&quot;   position: {0}, duration: {1}&quot;,  \n      audio.AudioPosition, audio.Duration);  \n  }  \n\n  // Add event handler code here.  \n}\n</code></pre>\r\n    \r\n    \r\n        </li>\r\n        <li class=\" enable-platform-filter\" id=\"System_Speech_Recognition_RecognizedAudio_Format\">\r\n    \r\n            <a id=\"System_Speech_Recognition_RecognizedAudio_Format_\"></a>\r\n    \r\n    \r\n          <div class=\"memberName\">\r\n            <div class=\"lang-csharp\">Format</div>        \r\n          </div>\r\n    \r\n            <p>Gets the format of the audio processed by a recognition engine.</p>\n\r\n    \r\n            <pre class=\"memberDeclaration\"><code class=\"csharp lang-csharp\">public System.Speech.AudioFormat.SpeechAudioFormatInfo Format { get; }</code></pre>\r\n    \r\n    \r\n    \r\n    \r\n              <h4>Property Value</h4>\r\n              <ul class=\"memberDetails\">\r\n                <li>\r\n                  <div class=\"single\">                \r\n                      <div class=\"lang-csharp\"><a class=\"xref\" href=\"system.speech.audioformat.speechaudioformatinfo\" data-linktype=\"relative-path\">SpeechAudioFormatInfo</a></div>\r\n                  </div>\r\n                  <p>The format of the audio processed by the speech recognizer.</p>\n\r\n                </li>\r\n              </ul>\r\n    \r\n    \r\n          \r\n    \r\n    \r\n            <h4>Example</h4>\r\n            <p>The following example handles the <a class=\"xref\" href=\"system.speech.recognition.speechrecognitionengine#System_Speech_Recognition_SpeechRecognitionEngine_SpeechRecognized\" data-linktype=\"relative-path\">System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized</a> or <a class=\"xref\" href=\"system.speech.recognition.speechrecognizer#System_Speech_Recognition_SpeechRecognizer_SpeechRecognized\" data-linktype=\"relative-path\">System.Speech.Recognition.SpeechRecognizer.SpeechRecognized</a> event and outputs to the console information about the recognized audio that is associated with the recognition result.  </p>\n<pre><code class=\"lang-c#\">\n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n\n  RecognitionResult result = e.Result;  \n\n  Console.WriteLine(&quot;Grammar({0}): {1}&quot;,  \n    result.Grammar.Name, result.Text);  \n\n  if (e.Result.Audio != null)  \n  {  \n    RecognizedAudio audio = e.Result.Audio;  \n\n    Console.WriteLine(&quot;   start time: {0}&quot;, audio.StartTime);  \n    Console.WriteLine(&quot;   encoding format: {0}&quot;, audio.Format.EncodingFormat);  \n    Console.WriteLine(&quot;   position: {0}, duration: {1}&quot;,  \n      audio.AudioPosition, audio.Duration);  \n  }  \n\n  // Add event handler code here.  \n}\n</code></pre>\r\n    \r\n    \r\n        </li>\r\n        <li class=\" enable-platform-filter\" id=\"System_Speech_Recognition_RecognizedAudio_StartTime\">\r\n    \r\n            <a id=\"System_Speech_Recognition_RecognizedAudio_StartTime_\"></a>\r\n    \r\n    \r\n          <div class=\"memberName\">\r\n            <div class=\"lang-csharp\">StartTime</div>        \r\n          </div>\r\n    \r\n            <p>Gets the system time at the start of the recognition operation.</p>\n\r\n    \r\n            <pre class=\"memberDeclaration\"><code class=\"csharp lang-csharp\">public DateTime StartTime { get; }</code></pre>\r\n    \r\n    \r\n    \r\n    \r\n              <h4>Property Value</h4>\r\n              <ul class=\"memberDetails\">\r\n                <li>\r\n                  <div class=\"single\">                \r\n                      <div class=\"lang-csharp\"><a class=\"xref\" href=\"system.datetime\" data-linktype=\"relative-path\">DateTime</a></div>\r\n                  </div>\r\n                  <p>The system time at the start of the recognition operation.</p>\n\r\n                </li>\r\n              </ul>\r\n    \r\n    \r\n          \r\n    \r\n            <h4>Remarks</h4>\r\n            <p>The StartTime property gets the system time at the start of the recognition operation, which can be useful for latency and performance calculations.  </p>\n<p> The <a class=\"xref\" href=\"system.speech.recognition.recognizedaudio#System_Speech_Recognition_RecognizedAudio_AudioPosition_\" data-linktype=\"relative-path\">AudioPosition</a> property gets the location in the input device&#39;s generated audio stream.</p>\n\r\n    \r\n            <h4>Example</h4>\r\n            <p>The following example handles the <a class=\"xref\" href=\"system.speech.recognition.speechrecognitionengine#System_Speech_Recognition_SpeechRecognitionEngine_SpeechRecognized\" data-linktype=\"relative-path\">System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized</a> or <a class=\"xref\" href=\"system.speech.recognition.speechrecognizer#System_Speech_Recognition_SpeechRecognizer_SpeechRecognized\" data-linktype=\"relative-path\">System.Speech.Recognition.SpeechRecognizer.SpeechRecognized</a> event and outputs to the console information about the recognized audio that is associated with the recognition result.  </p>\n<pre><code class=\"lang-c#\">\n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n\n  RecognitionResult result = e.Result;  \n\n  Console.WriteLine(&quot;Grammar({0}): {1}&quot;,  \n    result.Grammar.Name, result.Text);  \n\n  if (e.Result.Audio != null)  \n  {  \n    RecognizedAudio audio = e.Result.Audio;  \n\n    Console.WriteLine(&quot;   start time: {0}&quot;, audio.StartTime);  \n    Console.WriteLine(&quot;   encoding format: {0}&quot;, audio.Format.EncodingFormat);  \n    Console.WriteLine(&quot;   position: {0}, duration: {1}&quot;,  \n      audio.AudioPosition, audio.Duration);  \n  }  \n\n  // Add event handler code here.  \n}\n</code></pre>\r\n    \r\n    \r\n        </li>\r\n      </ul>\r\n    </section><section class=\"memberGroup\">\r\n      <header class=\"header enable-platform-filter\" id=\"methods\">\r\n        <h2>Methods\r\n    </h2>\r\n      </header>\r\n    \r\n      <ul class=\"list-clean enable-platform-filter\">\r\n    \r\n        <li class=\" enable-platform-filter\" id=\"System_Speech_Recognition_RecognizedAudio_GetRange_System_TimeSpan_System_TimeSpan_\">\r\n    \r\n            <a id=\"System_Speech_Recognition_RecognizedAudio_GetRange_\"></a>\r\n    \r\n    \r\n          <div class=\"memberName\">\r\n            <div class=\"lang-csharp\">GetRange(TimeSpan,TimeSpan)</div>        \r\n          </div>\r\n    \r\n            <p>Selects and returns a section of the current recognized audio as binary data.</p>\n\r\n    \r\n            <pre class=\"memberDeclaration\"><code class=\"csharp lang-csharp\">public System.Speech.Recognition.RecognizedAudio GetRange (TimeSpan audioPosition, TimeSpan duration);</code></pre>\r\n    \r\n    \r\n              <h4>Parameters</h4>\r\n              <ul class=\"memberDetails\">\r\n                <li>\r\n                  <dl>\r\n                  <dt>audioPosition</dt>\r\n                  <dd>\r\n                    <div class=\"lang-csharp\"><a class=\"xref\" href=\"system.timespan\" data-linktype=\"relative-path\">TimeSpan</a></div>\r\n                  </dd>\r\n                  </dl>\r\n                  <p>The starting point of the audio data to be returned.</p>\n\r\n                </li>\r\n                <li>\r\n                  <dl>\r\n                  <dt>duration</dt>\r\n                  <dd>\r\n                    <div class=\"lang-csharp\"><a class=\"xref\" href=\"system.timespan\" data-linktype=\"relative-path\">TimeSpan</a></div>\r\n                  </dd>\r\n                  </dl>\r\n                  <p>The length of the segment to be returned.</p>\n\r\n                </li>\r\n              </ul>\r\n    \r\n              <h4>Returns</h4>\r\n              <ul class=\"memberDetails\">\r\n                <li>\r\n                  <div class=\"single\">                \r\n                      <div class=\"lang-csharp\"><a class=\"xref\" href=\"system.speech.recognition.recognizedaudio\" data-linktype=\"relative-path\">RecognizedAudio</a></div>\r\n                  </div>\r\n                  <p>Returns a subsection of the recognized audio, as defined by <code>audioPosition</code> and <code>duration</code>.</p>\n\r\n                </li>\r\n              </ul>\r\n    \r\n    \r\n              <h4>Exceptions</h4>\r\n              <ul class=\"memberDetails\">\r\n                <li>\r\n                  <div class=\"single\">                \r\n                      <div class=\"lang-csharp\"><a class=\"xref\" href=\"system.argumentoutofrangeexception\" data-linktype=\"relative-path\">ArgumentOutOfRangeException</a></div>\r\n                  </div>\r\n                  <p><code>audioPosition</code> and <code>duration</code> define a segment of audio outside the range of the current segment.</p>\n\r\n                </li>\r\n                <li>\r\n                  <div class=\"single\">                \r\n                      <div class=\"lang-csharp\"><a class=\"xref\" href=\"system.invalidoperationexception\" data-linktype=\"relative-path\">InvalidOperationException</a></div>\r\n                  </div>\r\n                  <p>The current recognized audio contains no data.</p>\n\r\n                </li>\r\n              </ul>\r\n    \r\n          \r\n    \r\n    \r\n            <h4>Example</h4>\r\n            <p>The following example creates a speech recognition grammar for name input, adds a handler for the <a class=\"xref\" href=\"system.speech.recognition.grammar#System_Speech_Recognition_Grammar_SpeechRecognized\" data-linktype=\"relative-path\">SpeechRecognized</a> event, and loads the grammar into an in-process speech recognizer. Then it writes the audio information for the name portion of the input to an audio file. The audio file is used as input to a <a class=\"xref\" href=\"system.speech.synthesis.speechsynthesizer\" data-linktype=\"relative-path\">SpeechSynthesizer</a> object, which speaks a phrase that includes the recorded audio.  </p>\n<pre><code>private static void AddNameGrammar(SpeechRecognitionEngine recognizer)  \n{  \n  GrammarBuilder builder = new GrammarBuilder();  \n  builder.Append(&quot;My name is&quot;);  \n  builder.AppendWildcard();  \n\n  Grammar nameGrammar = new Grammar(builder);  \n  nameGrammar.Name = &quot;Name Grammar&quot;;  \n  nameGrammar.SpeechRecognized +=  \n    new EventHandler&lt;SpeechRecognizedEventArgs&gt;(  \n      NameSpeechRecognized);  \n\n  recognizer.LoadGrammar(nameGrammar);  \n}  \n\n// Handle the SpeechRecognized event of the name grammar.  \nprivate static void NameSpeechRecognized(  \n  object sender, SpeechRecognizedEventArgs e)  \n{  \n  Console.WriteLine(&quot;Grammar ({0}) recognized speech: {1}&quot;,  \n    e.Result.Grammar.Name, e.Result.Text);  \n\n  try  \n  {  \n\n    // The name phrase starts after the first three words.  \n    if (e.Result.Words.Count &lt; 4)  \n    {  \n\n      // Add code to check for an alternate that contains the wildcard.  \n      return;  \n    }  \n\n    RecognizedAudio audio = e.Result.Audio;  \n    TimeSpan start = e.Result.Words[3].AudioPosition;  \n    TimeSpan duration = audio.Duration - start;  \n\n    // Add code to verify and persist the audio.  \n    string path = @&quot;C:&nbsp;&nbsp;&nbsp;&nbsp;emp<br>ameAudio.wav&quot;;  \n    using (Stream outputStream = new FileStream(path, FileMode.Create))  \n    {  \n      RecognizedAudio nameAudio = audio.GetRange(start, duration);  \n      nameAudio.WriteToWaveStream(outputStream);  \n      outputStream.Close();  \n    }  \n\n    Thread testThread =  \n      new Thread(new ParameterizedThreadStart(TestAudio));  \n    testThread.Start(path);  \n  }  \n  catch (Exception ex)  \n  {  \n    Console.WriteLine(&quot;Exception thrown while processing audio:&quot;);  \n    Console.WriteLine(ex.ToString());  \n  }  \n}  \n\n// Use the speech synthesizer to play back the .wav file  \n// that was created in the SpeechRecognized event handler.  \n\nprivate static void TestAudio(object item)  \n{  \n  string path = item as string;  \n  if (path != null &amp;&amp; File.Exists(path))  \n  {  \n    SpeechSynthesizer synthesizer = new SpeechSynthesizer();  \n    PromptBuilder builder = new PromptBuilder();  \n    builder.AppendText(&quot;Hello&quot;);  \n    builder.AppendAudio(path);  \n    synthesizer.Speak(builder);  \n  }  \n}\n</code></pre>\r\n    \r\n    \r\n        </li>\r\n        <li class=\" enable-platform-filter\" id=\"System_Speech_Recognition_RecognizedAudio_WriteToAudioStream_System_IO_Stream_\">\r\n    \r\n            <a id=\"System_Speech_Recognition_RecognizedAudio_WriteToAudioStream_\"></a>\r\n    \r\n    \r\n          <div class=\"memberName\">\r\n            <div class=\"lang-csharp\">WriteToAudioStream(Stream)</div>        \r\n          </div>\r\n    \r\n            <p>Writes the entire audio to a stream as raw data.</p>\n\r\n    \r\n            <pre class=\"memberDeclaration\"><code class=\"csharp lang-csharp\">public void WriteToAudioStream (System.IO.Stream outputStream);</code></pre>\r\n    \r\n    \r\n              <h4>Parameters</h4>\r\n              <ul class=\"memberDetails\">\r\n                <li>\r\n                  <dl>\r\n                  <dt>outputStream</dt>\r\n                  <dd>\r\n                    <div class=\"lang-csharp\"><a class=\"xref\" href=\"system.io.stream\" data-linktype=\"relative-path\">Stream</a></div>\r\n                  </dd>\r\n                  </dl>\r\n                  <p>The stream that will receive the audio data.</p>\n\r\n                </li>\r\n              </ul>\r\n    \r\n    \r\n    \r\n    \r\n          \r\n    \r\n            <h4>Remarks</h4>\r\n            <p>Audio data is written to <code>outputStream</code> in binary form. No header information is included.  </p>\n<p> The WriteToAudioStream method uses the Wave format, but does not include the Wave header. To include the Wave header, use the <a class=\"xref\" href=\"system.speech.recognition.recognizedaudio#System_Speech_Recognition_RecognizedAudio_WriteToWaveStream_\" data-linktype=\"relative-path\">WriteToWaveStream</a> method.</p>\n\r\n    \r\n    \r\n    \r\n        </li>\r\n        <li class=\" enable-platform-filter\" id=\"System_Speech_Recognition_RecognizedAudio_WriteToWaveStream_System_IO_Stream_\">\r\n    \r\n            <a id=\"System_Speech_Recognition_RecognizedAudio_WriteToWaveStream_\"></a>\r\n    \r\n    \r\n          <div class=\"memberName\">\r\n            <div class=\"lang-csharp\">WriteToWaveStream(Stream)</div>        \r\n          </div>\r\n    \r\n            <p>Writes audio to a stream in Wave format.</p>\n\r\n    \r\n            <pre class=\"memberDeclaration\"><code class=\"csharp lang-csharp\">public void WriteToWaveStream (System.IO.Stream outputStream);</code></pre>\r\n    \r\n    \r\n              <h4>Parameters</h4>\r\n              <ul class=\"memberDetails\">\r\n                <li>\r\n                  <dl>\r\n                  <dt>outputStream</dt>\r\n                  <dd>\r\n                    <div class=\"lang-csharp\"><a class=\"xref\" href=\"system.io.stream\" data-linktype=\"relative-path\">Stream</a></div>\r\n                  </dd>\r\n                  </dl>\r\n                  <p>The stream that will receive the audio data.</p>\n\r\n                </li>\r\n              </ul>\r\n    \r\n    \r\n    \r\n    \r\n          \r\n    \r\n            <h4>Remarks</h4>\r\n            <p>Audio data is written to <code>outputStream</code> in Wave format, which includes a resource interchange file format (RIFF) header.  </p>\n<p> The <a class=\"xref\" href=\"system.speech.recognition.recognizedaudio#System_Speech_Recognition_RecognizedAudio_WriteToAudioStream_\" data-linktype=\"relative-path\">WriteToAudioStream</a> method uses the same binary format, but does not include the Wave header.</p>\n\r\n    \r\n            <h4>Example</h4>\r\n            <p>The following example creates a speech recognition grammar for name input, adds a handler for the <a class=\"xref\" href=\"system.speech.recognition.grammar#System_Speech_Recognition_Grammar_SpeechRecognized\" data-linktype=\"relative-path\">SpeechRecognized</a> event, and loads the grammar into an in-process speech recognizer. Then it writes the audio information for the name portion of the input to an audio file. The audio file is used as input to a <a class=\"xref\" href=\"system.speech.synthesis.speechsynthesizer\" data-linktype=\"relative-path\">SpeechSynthesizer</a> object, which speaks a phrase that includes the recorded audio.  </p>\n<pre><code>private static void AddNameGrammar(SpeechRecognitionEngine recognizer)  \n{  \n  GrammarBuilder builder = new GrammarBuilder();  \n  builder.Append(&quot;My name is&quot;);  \n  builder.AppendWildcard();  \n\n  Grammar nameGrammar = new Grammar(builder);  \n  nameGrammar.Name = &quot;Name Grammar&quot;;  \n  nameGrammar.SpeechRecognized +=  \n    new EventHandler&lt;SpeechRecognizedEventArgs&gt;(  \n      NameSpeechRecognized);  \n\n  recognizer.LoadGrammar(nameGrammar);  \n}  \n\n// Handle the SpeechRecognized event of the name grammar.  \nprivate static void NameSpeechRecognized(  \n  object sender, SpeechRecognizedEventArgs e)  \n{  \n  Console.WriteLine(&quot;Grammar ({0}) recognized speech: {1}&quot;,  \n    e.Result.Grammar.Name, e.Result.Text);  \n\n  try  \n  {  \n    // The name phrase starts after the first three words.  \n    if (e.Result.Words.Count &lt; 4)  \n    {  \n\n      // Add code to check for an alternate that contains the   \nwildcard.  \n      return;  \n    }  \n\n    RecognizedAudio audio = e.Result.Audio;  \n    TimeSpan start = e.Result.Words[3].AudioPosition;  \n    TimeSpan duration = audio.Duration - start;  \n\n    // Add code to verify and persist the audio.  \n    string path = @&quot;C:&nbsp;&nbsp;&nbsp;&nbsp;emp<br>ameAudio.wav&quot;;  \n    using (Stream outputStream = new FileStream(path, FileMode.Create))  \n    {  \n      RecognizedAudio nameAudio = audio.GetRange(start, duration);  \n      nameAudio.WriteToWaveStream(outputStream);  \n      outputStream.Close();  \n    }  \n\n    Thread testThread =  \n      new Thread(new ParameterizedThreadStart(TestAudio));  \n    testThread.Start(path);  \n  }  \n  catch (Exception ex)  \n  {  \n    Console.WriteLine(&quot;Exception thrown while processing audio:&quot;);  \n    Console.WriteLine(ex.ToString());  \n  }  \n}  \n\n// Use the speech synthesizer to play back the .wav file  \n// that was created in the SpeechRecognized event handler.  \n\nprivate static void TestAudio(object item)  \n{  \n  string path = item as string;  \n  if (path != null &amp;&amp; File.Exists(path))  \n  {  \n    SpeechSynthesizer synthesizer = new SpeechSynthesizer();  \n    PromptBuilder builder = new PromptBuilder();  \n    builder.AppendText(&quot;Hello&quot;);  \n    builder.AppendAudio(path);  \n    synthesizer.Speak(builder);  \n  }  \n}\n</code></pre>\r\n    \r\n    \r\n        </li>\r\n      </ul>\r\n    </section>\r\n    \r\n    \r\n    \r\n    \r\n    \r\n    \r\n    \r\n    \r\n    \r\n    \r\n","outputRootRelativePath":"./","pageMetadata":"<meta name=\"breadcrumb_path\" content=\"breadcrumb/toc1.json\">\r\n<meta name=\"search.ms_sitename\" content=\"Docs\">\r\n<meta name=\"search.ms_docsetname\" content=\"fulldocset\">\r\n<meta name=\"locale\" content=\"en-us\">\r\n<meta name=\"site_name\" content=\"Docs\">\r\n<meta name=\"search.ms_product\" content=\"MSDN\">\r\n<meta name=\"depot_name\" content=\"MSDN.fulldocset\">\r\n<meta name=\"ref_skeleton_gitcommit\" content=\"https://github.com/TianqiZhang/ECMA2YamlTestRepo2/blob/501959ac03e19ac52a27aa4c6bbeb980f8b11c8c/fulldocset/System.Speech.Recognition.RecognizedAudio.yml\">\r\n<meta name=\"original_ref_skeleton_git_url\" content=\"https://github.com/TianqiZhang/ECMA2YamlTestRepo2/blob/master/fulldocset/System.Speech.Recognition.RecognizedAudio.yml\">\r\n<meta name=\"APIName\" content=\"System.Speech.Recognition.RecognizedAudio\">\r\n<meta name=\"APIName\" content=\"System.Speech.Recognition.RecognizedAudio.AudioPosition\">\r\n<meta name=\"APIName\" content=\"System.Speech.Recognition.RecognizedAudio.Duration\">\r\n<meta name=\"APIName\" content=\"System.Speech.Recognition.RecognizedAudio.Format\">\r\n<meta name=\"APIName\" content=\"System.Speech.Recognition.RecognizedAudio.GetRange\">\r\n<meta name=\"APIName\" content=\"System.Speech.Recognition.RecognizedAudio.StartTime\">\r\n<meta name=\"APIName\" content=\"System.Speech.Recognition.RecognizedAudio.WriteToAudioStream\">\r\n<meta name=\"APIName\" content=\"System.Speech.Recognition.RecognizedAudio.WriteToWaveStream\">\r\n<meta name=\"APILocation\" content=\"System.Speech.dll\">\r\n<meta name=\"TopicType\" content=\"apiref\">\r\n<meta name=\"APIType\" content=\"Assembly\">\r\n<meta name=\"updated_at\" content=\"2017-03-01 01:37 AM\">\r\n<meta name=\"document_id\" content=\"8c7bd803-4735-dc63-9666-d287a5887d13\">\r\n<meta name=\"original_ecmaxml_local_path\" content=\"W:\\vejk\\s\\fulldocset\\xml\\System.Speech.Recognition\\RecognizedAudio.xml\">\r\n<meta name=\"pagetype\" content=\"Reference\">\r\n<meta name=\"description\" content=\"Represents audio input that is associated with a .\n\">\r\n<meta name=\"toc_rel\" content=\"_splitted/System.Speech.Recognition/toc1.json\">\r\n<meta name=\"source_url\" content=\"\">\r\n<meta name=\"ms.assetid\" content=\"System.Speech.Recognition.RecognizedAudio\">\r\n","rawMetadata":{"breadcrumb_path":"breadcrumb/toc.json","search.ms_sitename":"Docs","search.ms_docsetname":"fulldocset","version":null,"_op_canonicalUrlPrefix":"https://ppe.docs.microsoft.com/en-us/fulldotnet/","locale":"en-us","site_name":"Docs","search.ms_product":"MSDN","_op_openToPublicContributors":true,"depot_name":"MSDN.fulldocset","_op_gitRefSkeletonCommitHistory":[{"author_name":"Tianqi Zhang","author_email":"tianzh@microsoft.com","committer_name":"Tianqi Zhang","comitter_email":"tianzh@microsoft.com","message":"use plugin in master","commit_sha":"501959ac03e19ac52a27aa4c6bbeb980f8b11c8c","commit_date":"2017-03-01 09:31:20 +0800"},{"author_name":"Tianqi Zhang","author_email":"tianzh@microsoft.com","committer_name":"Tianqi Zhang","comitter_email":"tianzh@microsoft.com","message":"switch from platform to version","commit_sha":"78cdacb5ca782478af490a6b30c3a2cb2b6b873e","commit_date":"2017-02-28 15:09:51 +0800"},{"author_name":"Tianqi Zhang","author_email":"tianzh@microsoft.com","committer_name":"Tianqi Zhang","comitter_email":"tianzh@microsoft.com","message":"update platforms","commit_sha":"39ad5a8919a59afc93a79ac4bd8e07c3b471b37a","commit_date":"2017-02-28 10:38:59 +0800"},{"author_name":"Tianqi Zhang","author_email":"tianzh@microsoft.com","committer_name":"Tianqi Zhang","comitter_email":"tianzh@microsoft.com","message":"checkin yml","commit_sha":"da161b792852497df7140d7768cee2eccd9cb43f","commit_date":"2017-02-28 09:36:15 +0800"},{"author_name":"Tianqi Zhang","author_email":"tianzh@microsoft.com","committer_name":"Tianqi Zhang","comitter_email":"tianzh@microsoft.com","message":"delete ymls","commit_sha":"417c04fd1daf0cb211ec4909020356fc1fe69260","commit_date":"2017-02-27 14:12:48 +0800"},{"author_name":"Tianqi Zhang","author_email":"tianzh@microsoft.com","committer_name":"Tianqi Zhang","comitter_email":"tianzh@microsoft.com","message":"update latest xml","commit_sha":"1e40a158586a88a698e0cb5342785002a56898b2","commit_date":"2017-02-24 16:20:57 +0800"},{"author_name":"Tianqi Zhang","author_email":"tianzh@microsoft.com","committer_name":"Tianqi Zhang","comitter_email":"tianzh@microsoft.com","message":"add exceptions to reference section","commit_sha":"2f337ac32baa36b4ee4b5d8987b29dba4ce77336","commit_date":"2017-02-24 11:22:25 +0800"},{"author_name":"Tianqi Zhang","author_email":"tianzh@microsoft.com","committer_name":"Tianqi Zhang","comitter_email":"tianzh@microsoft.com","message":"transform see cref and fix paramref format","commit_sha":"3d0ea34483c97ac77f4020a7f294757d67a5c1d4","commit_date":"2017-02-23 10:03:17 +0800"},{"author_name":"Tianqi Zhang","author_email":"tianzh@microsoft.com","committer_name":"Tianqi Zhang","comitter_email":"tianzh@microsoft.com","message":"convert exceptions","commit_sha":"0a5bf3370731dd35a596c91081e5dc82e2eace3a","commit_date":"2017-02-22 11:54:30 +0800"},{"author_name":"Tianqi Zhang","author_email":"tianzh@microsoft.com","committer_name":"Tianqi Zhang","comitter_email":"tianzh@microsoft.com","message":"remove _yml from url","commit_sha":"f9314af8858edb8c329d223328490093aef4f55f","commit_date":"2017-02-17 15:31:12 +0800"}],"ref_skeleton_gitcommit":"https://github.com/TianqiZhang/ECMA2YamlTestRepo2/blob/501959ac03e19ac52a27aa4c6bbeb980f8b11c8c/fulldocset/System.Speech.Recognition.RecognizedAudio.yml","original_ref_skeleton_git_url":"https://github.com/TianqiZhang/ECMA2YamlTestRepo2/blob/master/fulldocset/System.Speech.Recognition.RecognizedAudio.yml","open_to_public_contributors":true,"api_name":["System.Speech.Recognition.RecognizedAudio","System.Speech.Recognition.RecognizedAudio.AudioPosition","System.Speech.Recognition.RecognizedAudio.Duration","System.Speech.Recognition.RecognizedAudio.Format","System.Speech.Recognition.RecognizedAudio.GetRange","System.Speech.Recognition.RecognizedAudio.StartTime","System.Speech.Recognition.RecognizedAudio.WriteToAudioStream","System.Speech.Recognition.RecognizedAudio.WriteToWaveStream"],"api_location":["System.Speech.dll"],"topic_type":["apiref"],"api_type":["Assembly"],"f1_keywords":["System.Speech.Recognition.RecognizedAudio","System::Speech::Recognition::RecognizedAudio","System.Speech.Recognition.RecognizedAudio.AudioPosition","System::Speech::Recognition::RecognizedAudio::AudioPosition","System.Speech.Recognition.RecognizedAudio.Duration","System::Speech::Recognition::RecognizedAudio::Duration","System.Speech.Recognition.RecognizedAudio.Format","System::Speech::Recognition::RecognizedAudio::Format","System.Speech.Recognition.RecognizedAudio.GetRange","System::Speech::Recognition::RecognizedAudio::GetRange","System.Speech.Recognition.RecognizedAudio.StartTime","System::Speech::Recognition::RecognizedAudio::StartTime","System.Speech.Recognition.RecognizedAudio.WriteToAudioStream","System::Speech::Recognition::RecognizedAudio::WriteToAudioStream","System.Speech.Recognition.RecognizedAudio.WriteToWaveStream","System::Speech::Recognition::RecognizedAudio::WriteToWaveStream"],"dev_langs":["csharp"],"updated_at":"2017-03-01 01:37 AM","document_id":"8c7bd803-4735-dc63-9666-d287a5887d13","original_ecmaxml_local_path":"W:\\vejk\\s\\fulldocset\\xml\\System.Speech.Recognition\\RecognizedAudio.xml","content_git_url":"https://github.com/TianqiZhang/ECMA2YamlTestRepo2/blob/master/fulldocset/xml/System.Speech.Recognition/RecognizedAudio.xml","layout":"Reference","_op_layout":"Reference","pagetype":"Reference","title":"RecognizedAudio class | Microsoft Docs","_op_ogTitle":"RecognizedAudio class","description":"Represents audio input that is associated with a .\n","toc_asset_id":"_splitted/System.Speech.Recognition/toc.json","toc_rel":"_splitted/System.Speech.Recognition/toc.json","source_url":"","ms.assetid":"System.Speech.Recognition.RecognizedAudio","canonical_url":"https://ppe.docs.microsoft.com/en-us/mergedepotdynamic/system.speech.recognition.recognizedaudio","_op_canonicalUrl":"https://ppe.docs.microsoft.com/en-us/mergedepotdynamic/system.speech.recognition.recognizedaudio","fileRelativePath":"System.Speech.Recognition.RecognizedAudio.html"},"themesRelativePathToOutputRoot":"_themes/"}